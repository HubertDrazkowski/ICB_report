{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb1b060",
   "metadata": {},
   "source": [
    "# Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce93e6-1cd1-437c-b368-d3e6ffee3bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb0829-7f16-40b1-8d53-e8c796ec49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97c1b3-56e8-4e36-9eb0-76a3a825fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature generation\n",
    "np.random.seed(7)  # For reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dab05c6-8520-4760-93a1-602a7ade4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_xr_MELD(T=500, A=2, K=4, sigma=0.10):\n",
    "    '''\n",
    "    Simulating synthetic data. Inspired by semisynthetic MELD example from (Huyuk, 2022)\n",
    "    '''\n",
    "    # Initialize the context matrix\n",
    "    data_x = np.zeros((T, A, K))\n",
    "    \n",
    "    # Define periods for MELD-based policy\n",
    "    period_pre_MELD = range(0, T // 3)\n",
    "    period_MELD = range(T // 3, 2 * T // 3)\n",
    "    period_post_MELD = range(2 * T // 3, T)\n",
    "    \n",
    "    # Generate context data\n",
    "    for t in range(T):\n",
    "        for a in range(A):\n",
    "            waiting_time = np.random.exponential(scale=20)\n",
    "            creatinine, INR, bilirubin = np.random.lognormal(mean=1, sigma=0.5, size=3)\n",
    "            data_x[t, a, :] = [waiting_time, creatinine, INR, bilirubin]\n",
    "    \n",
    "    # Reward generation based on policy period\n",
    "    rewards = np.zeros((T, A))\n",
    "    for t in range(T):\n",
    "        for a in range(A):\n",
    "            if t in period_pre_MELD:\n",
    "                rewards[t, a] = data_x[t, a, 0] + np.log(data_x[t, a, 1])\n",
    "            elif t in period_MELD:\n",
    "                rewards[t, a] = 9.57 * np.log(data_x[t, a, 1]) + 11.2 * np.log(data_x[t, a, 2]) + 3.78 * np.log(data_x[t, a, 3])\n",
    "            else:  # post_MELD\n",
    "                rewards[t, a] = data_x[t, a, 0] + np.log(data_x[t, a, 2]) + np.log(data_x[t, a, 3])\n",
    "            rewards[t, a] += np.random.normal(loc=0, scale=np.sqrt(sigma))\n",
    "    \n",
    "    return data_x, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473055e-1932-4ca8-ad22-a61b8a9496fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALGORITHMS AND THEIR POLICIES\n",
    "def optimistic(beta_mean, x, beta_cov, alpha):\n",
    "    '''\n",
    "    Softmax on ucb like choices\n",
    "    '''\n",
    "    q = alpha * np.einsum('ij,j->i', x, beta_mean) + np.einsum('ij,jk,ki->i', x, beta_cov, x.T)\n",
    "    prob = np.exp(q - logsumexp(q))\n",
    "    return np.random.choice(np.arange(x.shape[0]), p=prob)\n",
    "\n",
    "def softmax(beta_mean, x, alpha):\n",
    "    '''\n",
    "    Softmax on greedy like choices\n",
    "    '''    \n",
    "    q = alpha * np.einsum('ij,j->i', x, beta_mean)\n",
    "    prob = np.exp(q - logsumexp(q))\n",
    "    return np.random.choice(np.arange(x.shape[0]), p=prob)\n",
    "\n",
    "def greedy(beta_mean, x, alpha):\n",
    "    '''\n",
    "    Greedy choices\n",
    "    '''    \n",
    "    q = np.einsum('ij,j->i', x, beta_mean)\n",
    "    return np.argmax(q)\n",
    "\n",
    "def ucb(beta_mean, x, beta_cov, alpha):\n",
    "    '''\n",
    "    UCB choices\n",
    "    '''    \n",
    "    pred = np.einsum('ij,j->i', x, beta_mean)\n",
    "    unc = np.sqrt(np.einsum('ij,jk,ki->i', x, beta_cov, x.T))\n",
    "    q = pred + alpha * unc\n",
    "    return np.argmax(q)\n",
    "\n",
    "def ts(beta_mean, x, beta_cov, alpha,  num_samples=10):\n",
    "    '''\n",
    "    TS Monte Carlo version choices\n",
    "    '''    \n",
    "    K = beta_mean.shape[0]  # Number of features\n",
    "    A = x.shape[0]  # Number of actions\n",
    "\n",
    "    # Result(num_samples, K)\n",
    "    sampled_rhos = np.random.multivariate_normal(beta_mean, beta_cov, size=num_samples)\n",
    "    \n",
    "    # x to (1, A, K) and broadcasted \n",
    "    # Result shape (num_samples, A)\n",
    "    scores = np.dot(sampled_rhos, x.T)\n",
    "\n",
    "    # Result shape (num_samples,)\n",
    "    best_actions = np.argmax(scores, axis=1)\n",
    "    \n",
    "#    counts = np.bincount(best_actions, minlength=A)\n",
    "#    freq = best_action_counts / num_samples\n",
    "    freq=np.zeros(A)\n",
    "    for action in range(A):\n",
    "        freq[action] = np.sum(best_actions == action) / num_samples\n",
    "        \n",
    "    return np.random.choice(np.arange(x.shape[0]), p=freq)\n",
    "\n",
    "def igw(beta_mean, x, alpha):\n",
    "    '''\n",
    "    IGW choices\n",
    "    '''             \n",
    "    erewards = np.einsum('ij,j->i', x, beta_mean)  # prediction\n",
    "    best_arm = np.argmax(erewards)\n",
    "    gaps = erewards[best_arm] - erewards  # Gaps\n",
    "\n",
    "    A = x.shape[0]  # x is (A, K)\n",
    "    # Compute the prob for non-best \n",
    "    pi = 1 / (A + alpha * gaps)\n",
    "    pi[best_arm] = 0  # temp\n",
    "\n",
    "    # Adjust the best arm\n",
    "    pi_best = 1 - np.sum(pi)\n",
    "    pi[best_arm] = pi_best\n",
    "\n",
    "    return np.random.choice(np.arange(x.shape[0]), p=pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e781c-1ef9-4a8c-a649-6d21dda67809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_wrapper(algo_name, beta_mean, x, beta_cov, alpha, **kwargs):\n",
    "    if algo_name in [\"greedy\", \"igw\", \"softmax\"]:\n",
    "        # algo do not use beta_cov\n",
    "        return globals()[algo_name](beta_mean, x, alpha=alpha, **kwargs)\n",
    "    elif algo_name in [\"ucb\", \"ts\", \"optimistic\"]:\n",
    "        # algo use beta_cov\n",
    "        return globals()[algo_name](beta_mean, x, beta_cov, alpha=alpha, **kwargs)\n",
    "    else:\n",
    "        # Default case\n",
    "        return globals()[algo_name](beta_mean, x, beta_cov, alpha=alpha, **kwargs)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5341dd-e472-49de-9659-7c562afc643d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c06100e-9c6b-433e-86e4-add057d8fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data_x, rewards, algo, sigma, alpha):\n",
    "    '''\n",
    "    Wrapper for the algorithms run:\n",
    "    1) Unpacks the initial values and sets the parameters\n",
    "    2) Orchestrates algorithm choices\n",
    "    3) Outputs the samples collected\n",
    "    '''\n",
    "\n",
    "    T, A, K = data_x.shape\n",
    "    sigma  = 0.10\n",
    "    hyper  = {'beta0_y': -np.ones(K)/K * (T//50), 'beta0_N': np.eye(K) * (T//50)}\n",
    "    beta_y = hyper['beta0_y']\n",
    "    beta_N = hyper['beta0_N']    \n",
    "    data   = {'x': [], 'a': [], 'rhox': [], 'betas_mean': []}\n",
    "    data['betas_mean'] = list()\n",
    "    data['betas_cov']  = list()\n",
    "    \n",
    "    # Run the algorithm for T rounds\n",
    "    for t in range(T):\n",
    "        # beliefs\n",
    "        beta_mean = np.linalg.inv(beta_N) @ beta_y            \n",
    "        beta_cov = sigma**2 * np.linalg.inv(beta_N)\n",
    "            \n",
    "        # (x,a,r)\n",
    "        x = data_x[t]            \n",
    "        a = algo_wrapper(algo, beta_mean, x, beta_cov, alpha)            \n",
    "        r = rewards[t, a]\n",
    "        \n",
    "        # Update data and beliefs\n",
    "        data['x'].append(x)\n",
    "        data['a'].append(a)\n",
    "        data['betas_mean'].append(beta_mean)\n",
    "        data['betas_cov'].append(beta_cov)\n",
    "\n",
    "        # Update beliefs utilities\n",
    "        beta_y = beta_y + r * x[a]\n",
    "        beta_N = beta_N + np.einsum('i,j->ij', x[a], x[a])\n",
    "                            \n",
    "        # After, calc rho_env\n",
    "        rhox = np.linalg.inv(beta_N) @ beta_y\n",
    "        data['rhox'] = (rhox / np.abs(rhox).sum()).tolist()\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b5ed1-1916-4261-8850-88183af5a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../Datasets\"\n",
    "algos = [\"igw\", \"optimistic\", \"softmax\", \"greedy\", \"ucb\", \"ts\"]\n",
    "alpha = 20\n",
    "T=1000\n",
    "A=3\n",
    "K=4\n",
    "sigma=0.10\n",
    "\n",
    "for i in range(11, 100):\n",
    "    data_x, rewards = gen_xr_MELD(T=T, A=A, K=K, sigma=sigma)\n",
    "\n",
    "    for algo in algos:\n",
    "        # Run the experiment and get results\n",
    "        experiment_data = run_experiment(data_x, rewards, algo, sigma=0.10, alpha=alpha)\n",
    "\n",
    "        # Save the results\n",
    "        filename = f'{output_dir}/dataset_{i}_{algo}.dill'\n",
    "        with open(filename, 'wb') as f:\n",
    "            dill.dump(experiment_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca8dc29-7094-420d-b0f2-97047570c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and load the data from the .diller\n",
    "for i in range(1):\n",
    "    file_path = f'{output_dir}/dataset_{i}_{algo}.dill'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    data = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f6b549-8386-4929-a65d-a45a8ca05b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check is everything ok?\n",
    "data_x = np.array(data['x'])  \n",
    "data_a = np.array(data['a'])  \n",
    "rhox = data['rhox']           \n",
    "betas_mean = data['betas_mean']  \n",
    "betas_cov=data['betas_cov']\n",
    "\n",
    "print(\"Contexts (data_x):\", data_x)\n",
    "print(\"Actions (data_a):\", data_a)\n",
    "print(\"Estimated rhox:\", rhox)\n",
    "print(\"Beta means:\", betas_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
